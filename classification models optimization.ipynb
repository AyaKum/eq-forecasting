{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8314778,"sourceType":"datasetVersion","datasetId":4939130}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score, explained_variance_score, median_absolute_error\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\nfrom sklearn.svm import SVC \nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport folium\nimport pandas as pd\nfrom datetime import datetime\nimport requests\nfrom io import StringIO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, confusion_matrix\nfrom imblearn.over_sampling import ADASYN\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define the API endpoint URL\napi_url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n\ncurrent_time = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')\n\n# Define the parameters\nparams = {\n    'format': 'csv',\n    'starttime': '1960-01-01',\n    'endtime': current_time,\n    'latitude': 43.2,\n    'longitude': 78.7,\n    'maxradiuskm': 500,\n    'minmagnitude': 3,\n    'orderby': 'time'\n}\n\n# Make the API request\nresponse = requests.get(api_url, params=params)\n\n# Check if the request was successful (status code 200)\nif response.status_code == 200:\n    # Convert CSV data to Pandas DataFrame\n    data = pd.read_csv(StringIO(response.text))\n    \n    # Save the DataFrame to a CSV file\n    data.to_csv('earthquake_dataset_shelek.csv', index=False)\n\n    # Print the first few rows of the DataFrame\n    print(data.head())\nelse:\n    # Print an error message if the request was not successful\n    print(f\"Error: {response.status_code} - {response.text}\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = {\n    'latitude': data.latitude, 'longitude': data.longitude,  'depth': data.depth, \n    'time': pd.to_datetime(data['time']),\n    'year': pd.DatetimeIndex(data['time']).year, 'month': pd.DatetimeIndex(data['time']).month,'day': pd.DatetimeIndex(data['time']).day, 'hour': pd.DatetimeIndex(data['time']).hour,\n    'magnitude': data.mag}\n\ndf = pd.DataFrame(df)\n# data = data.set_index('time')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['rolling_mean_magnitude'] = df['magnitude'].rolling(window=10, min_periods=1).mean()\ndf['time_since_last_hour'] = df['time'].diff().dt.total_seconds().div(3600).abs()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isna().sum())\ndf = df.fillna(0)\nprint(df.isna().sum())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from geopy.distance import geodesic\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining significant earthquakes\nsignificant_threshold = 6.0\nsignificant_earthquakes = df[df['magnitude'] >= significant_threshold].copy()\n\n# Ensuring the time is in datetime format if not already\ndf['time'] = pd.to_datetime(df['time'])\nsignificant_earthquakes['time'] = pd.to_datetime(significant_earthquakes['time'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_closest_earthquake(row, significant_df):\n    # Calculate distances\n    distances = significant_df.apply(lambda x: geodesic((x['latitude'], x['longitude']), (row['latitude'], row['longitude'])).kilometers, axis=1)\n    min_distance_index = distances.idxmin()\n    closest_earthquake = significant_df.loc[min_distance_index]\n\n    # Calculate time difference in days\n    time_difference = abs((closest_earthquake['time'] - row['time']).total_seconds() / 86400)\n\n    return pd.Series([closest_earthquake['time'], min_distance_index, distances[min_distance_index], time_difference])\n\n# Apply the function to each row\ndf[['closest_eq_time', 'closest_eq_index', 'distance_to_closest_eq', 'time_diff_to_closest_eq']] = df.apply(find_closest_earthquake, significant_df=significant_earthquakes, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isna().sum())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df = pd.read_csv('dataset with new features.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.set_index('time', inplace=False)\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(['hour', 'closest_eq_time', 'closest_eq_index'], axis=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['magnitude'] = df['magnitude'].apply(lambda x: 1 if x >= 4.5 else 0)\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_counts = df['magnitude'].value_counts()\nplt.bar(class_counts.index, class_counts.values)\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.title('Class Distribution')\nplt.xticks([0, 1], ['Magnitude < 4.5', 'Magnitude >= 4.5'])\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df.drop('magnitude', axis=1)\nscaler = RobustScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n#print(X)\n\ny = df['magnitude']\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space = {\n    'n_neighbors': (5, 300),  # Adjust the upper limit accordingly\n    'weights': ['uniform', 'distance'],\n    'p': (1, 2),\n    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n    'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n}\n\n\n# Initialize the k-Nearest Neighbors Regressor\nknn = KNeighborsClassifier()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search = BayesSearchCV(\n    knn,\n    param_space,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric to minimize (negative MSE)\n    n_jobs=-3\n)\n\nnp.int = int\n# Fit the Bayesian optimization model\nbayes_search.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params = bayes_search.best_params_\nbest_score = bayes_search.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters:\", best_params)\nprint(\"Best Train Score:\", best_score)\n\n\n# You can also access the best model via bayes_search.best_estimator_\nbest_model = bayes_search.best_estimator_\n\n# Evaluate the model on the test set\ny_pred = best_model.predict(X_test)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_pred)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob = best_model.predict_proba(X_test)[:, 1]\nlogloss = log_loss(y_test, y_pred_prob)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\nprint(\"AUC-ROC:\", roc_auc)\nprint(\"Log Loss:\", logloss)\nprint(f'True Positives (TP): {TP}')\nprint(f'True Negatives (TN): {TN}')\nprint(f'False Positives (FP): {FP}')\nprint(f'False Negatives (FN): {FN}')\n\ny_pred_train = best_model.predict(X_train)\n\ntrain_accuracy = accuracy_score(y_train, y_pred_train)\nprint(\"Train accuracy:\", train_accuracy)\n\nclass_counts = y_test.value_counts()\nprint(class_counts)\n\n\naccuracy = accuracy_score(y_pred, y_test)\nprint(\"Accuracy:\", accuracy)\n\n# Save results\ndf_results = pd.DataFrame({\n    \"Model\": [\"KNN\"],\n    \"Best Train Score\": [best_score],\n    \"Train Accuracy\": [train_accuracy],\n    \"Test Accuracy\": [accuracy],\n    \"Precision\": [precision],\n    \"Recall\": [recall],\n    \"F1 Score\": [f1],\n    \"AUC-ROC\": [roc_auc],\n    \"Log Loss\": [logloss],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space_svm = {\n    'C': (0.001, 100),\n    'kernel': ['rbf', 'linear'],\n    'gamma': ['scale', 'auto'],\n    'degree': (1, 5),\n    'coef0': (0, 1)\n}\n\n# Initialize SVM Classifier\nsvm_classifier = SVC()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search_svm = BayesSearchCV(\n    svm_classifier,\n    param_space_svm,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric for SVM classifier\n    n_jobs=-3\n)\n\n# Fit the Bayesian optimization model\nbayes_search_svm.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params_svm = bayes_search_svm.best_params_\nbest_score_svm = bayes_search_svm.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters (SVM):\", best_params_svm)\nprint(\"Best Train Score (SVM):\", best_score_svm)\n\n# You can also access the best model via bayes_search_svm.best_estimator_\nbest_model_svm = bayes_search_svm.best_estimator_\n\n# Evaluate the model on the test set\ny_pred_svm = best_model_svm.predict(X_test)\nprecision_svm = precision_score(y_test, y_pred_svm)\nrecall_svm = recall_score(y_test, y_pred_svm)\nf1_svm = f1_score(y_test, y_pred_svm)\nroc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob_svm = best_model_svm.decision_function(X_test)\nlogloss_svm = log_loss(y_test, y_pred_prob_svm)\nconf_matrix = confusion_matrix(y_test, y_pred_svm)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision (SVM):\", precision_svm)\nprint(\"Recall (SVM):\", recall_svm)\nprint(\"F1 Score (SVM):\", f1_svm)\nprint(\"AUC-ROC (SVM):\", roc_auc_svm)\nprint(\"Log Loss (SVM):\", logloss_svm)\nprint(f'True Positives (TP) (SVM): {TP}')\nprint(f'True Negatives (TN) (SVM): {TN}')\nprint(f'False Positives (FP) (SVM): {FP}')\nprint(f'False Negatives (FN) (SVM): {FN}')\ny_pred_train_svm = best_model_svm.predict(X_train)\n\ntrain_accuracy_svm = accuracy_score(y_train, y_pred_train_svm)\nprint(\"Train accuracy (SVM):\", train_accuracy_svm)\n\nclass_counts_svm = y_test.value_counts()\nprint(class_counts_svm)\n\naccuracy_svm = accuracy_score(y_pred_svm, y_test)\nprint(\"Accuracy (SVM):\", accuracy_svm)\n\n# Save results\ndf_results = pd.concat([df_results, pd.DataFrame({\n    \"Model\": [\"SVM\"],\n    \"Best Train Score\": [best_score_svm],\n    \"Train Accuracy\": [train_accuracy_svm],\n    \"Test Accuracy\": [accuracy_svm],\n    \"Precision\":[precision_svm],\n    \"Recall\": [recall_svm],\n    \"F1 Score\": [f1_svm],\n    \"AUC-ROC\": [roc_auc_svm],\n    \"Log Loss\": [logloss_svm],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space_ada = {\n    'n_estimators': (50, 500),\n    'learning_rate': (0.01, 10),\n    'algorithm': ['SAMME', 'SAMME.R']\n}\n\n# Initialize AdaBoost Classifier\nada_classifier = AdaBoostClassifier()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search_ada = BayesSearchCV(\n    ada_classifier,\n    param_space_ada,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric for AdaBoost classifier\n    n_jobs=-3\n)\n\n# Fit the Bayesian optimization model\nbayes_search_ada.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params_ada = bayes_search_ada.best_params_\nbest_score_ada = bayes_search_ada.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters (AdaBoost):\", best_params_ada)\nprint(\"Best Train Score (AdaBoost):\", best_score_ada)\n\n# You can also access the best model via bayes_search_ada.best_estimator_\nbest_model_ada = bayes_search_ada.best_estimator_\n\n# Evaluate the model on the test set\ny_pred_ada = best_model_ada.predict(X_test)\nprecision_ada = precision_score(y_test, y_pred_ada)\nrecall_ada = recall_score(y_test, y_pred_ada)\nf1_ada = f1_score(y_test, y_pred_ada)\nroc_auc_ada = roc_auc_score(y_test, y_pred_ada)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob_ada = best_model_ada.predict_proba(X_test)[:, 1]\nlogloss_ada = log_loss(y_test, y_pred_prob_ada)\nconf_matrix = confusion_matrix(y_test, y_pred_ada)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision (AdaBoost):\", precision_ada)\nprint(\"Recall (AdaBoost):\", recall_ada)\nprint(\"F1 Score (AdaBoost):\", f1_ada)\nprint(\"AUC-ROC (AdaBoost):\", roc_auc_ada)\nprint(\"Log Loss (AdaBoost):\", logloss_ada)\nprint(f'True Positives (TP) (AdaBoost): {TP}')\nprint(f'True Negatives (TN) (AdaBoost): {TN}')\nprint(f'False Positives (FP) (AdaBoost): {FP}')\nprint(f'False Negatives (FN) (AdaBoost): {FN}')\ny_pred_train_ada = best_model_ada.predict(X_train)\n\ntrain_accuracy_ada = accuracy_score(y_train, y_pred_train_ada)\nprint(\"Train accuracy (AdaBoost):\", train_accuracy_ada)\n\nclass_counts_ada = y_test.value_counts()\nprint(class_counts_ada)\n\naccuracy_ada = accuracy_score(y_pred_ada, y_test)\nprint(\"Accuracy (AdaBoost):\", accuracy_ada)\n\n# Save results\ndf_results = pd.concat([df_results, pd.DataFrame({\n    \"Model\": [\"AdaBoost\"],\n    \"Best Train Score\": [best_score_ada],\n    \"Train Accuracy\": [train_accuracy_ada],\n    \"Test Accuracy\": [accuracy_ada],\n    \"Precision\":[precision_ada],\n    \"Recall\": [recall_ada],\n    \"F1 Score\": [f1_ada],\n    \"AUC-ROC\": [roc_auc_ada],\n    \"Log Loss\": [logloss_ada],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space_gb = {\n    'n_estimators': (50, 500),\n    'learning_rate': (0.01, 10),\n    'max_depth': (1, 50),\n    'min_samples_split': (2, 10),\n    'min_samples_leaf': (1, 10),\n    'max_features': ['sqrt', 'log2', None]\n}\n\n# Initialize Gradient Boosting Classifier\ngb_classifier = GradientBoostingClassifier()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search_gb = BayesSearchCV(\n    gb_classifier,\n    param_space_gb,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric for Gradient Boosting classifier\n    n_jobs=-3\n)\n\n# Fit the Bayesian optimization model\nbayes_search_gb.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params_gb = bayes_search_gb.best_params_\nbest_score_gb = bayes_search_gb.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters (Gradient Boosting):\", best_params_gb)\nprint(\"Best Train Score (Gradient Boosting):\", best_score_gb)\n\n# You can also access the best model via bayes_search_gb.best_estimator_\nbest_model_gb = bayes_search_gb.best_estimator_\n\n# Evaluate the model on the test set\ny_pred_gb = best_model_gb.predict(X_test)\nprecision_gb = precision_score(y_test, y_pred_gb)\nrecall_gb = recall_score(y_test, y_pred_gb)\nf1_gb = f1_score(y_test, y_pred_gb)\nroc_auc_gb = roc_auc_score(y_test, y_pred_gb)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob_gb = best_model_gb.predict_proba(X_test)[:, 1]\nlogloss_gb = log_loss(y_test, y_pred_prob_gb)\nconf_matrix = confusion_matrix(y_test, y_pred_gb)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision (Gradient Boosting):\", precision_gb)\nprint(\"Recall (Gradient Boosting):\", recall_gb)\nprint(\"F1 Score (Gradient Boosting):\", f1_gb)\nprint(\"AUC-ROC (Gradient Boosting):\", roc_auc_gb)\nprint(\"Log Loss (Gradient Boosting):\", logloss_gb)\nprint(f'True Positives (TP) (Gradient Boosting): {TP}')\nprint(f'True Negatives (TN) (Gradient Boosting): {TN}')\nprint(f'False Positives (FP) (Gradient Boosting): {FP}')\nprint(f'False Negatives (FN) (Gradient Boosting): {FN}')\ny_pred_train_gb = best_model_gb.predict(X_train)\n\ntrain_accuracy_gb = accuracy_score(y_train, y_pred_train_gb)\nprint(\"Trainaccuracy (Gradient Boosting):\", train_accuracy_gb)\n\nclass_counts_gb = y_test.value_counts()\nprint(class_counts_gb)\n\naccuracy_gb = accuracy_score(y_pred_gb, y_test)\nprint(\"Accuracy (Gradient Boosting):\", accuracy_gb)\n\n# Save results\ndf_results = pd.concat([df_results, pd.DataFrame({\n    \"Model\": [\"Gradient Boosting\"],\n    \"Best Train Score\": [best_score_gb],\n    \"Train Accuracy\": [train_accuracy_gb],\n    \"Test Accuracy\": [accuracy_gb],\n    \"Precision\":[precision_gb],\n    \"Recall\": [recall_gb],\n    \"F1 Score\": [f1_gb],\n    \"AUC-ROC\": [roc_auc_gb],\n    \"Log Loss\": [logloss_gb],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space = {\n    'C': (1e-6, 1e+6, 'log-uniform'),  # Regularization parameter\n    'penalty': ['l2'],  # Penalty type\n    'solver': ['lbfgs'],  # Optimization algorithm\n    'class_weight': ['balanced', None],  # Class weights for imbalanced data\n    'multi_class': ['ovr', 'multinomial'],  # Multiclass strategy\n    'warm_start': [True, False]  # Reuse solution of previous call\n}\n\n\n# Initialize Logistic Regression\nlogreg = LogisticRegression()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search_logreg = BayesSearchCV(\n    logreg,\n    param_space,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric for logistic regression\n    n_jobs=-3\n)\n\n# Fit the Bayesian optimization model\nbayes_search_logreg.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params_logreg = bayes_search_logreg.best_params_\nbest_score_logreg = bayes_search_logreg.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters:\", best_params_logreg)\nprint(\"Best Train Score:\", best_score_logreg)\n\n# You can also access the best model via bayes_search_logreg.best_estimator_\nbest_model_logreg = bayes_search_logreg.best_estimator_\n\n# Evaluate the model on the test set\ny_pred_logreg = best_model_logreg.predict(X_test)\nprecision_logreg = precision_score(y_test, y_pred_logreg)\nrecall_logreg = recall_score(y_test, y_pred_logreg)\nf1_logreg = f1_score(y_test, y_pred_logreg)\nroc_auc_logreg = roc_auc_score(y_test, y_pred_logreg)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob_logreg = best_model_logreg.predict_proba(X_test)[:, 1]\nlogloss_logreg = log_loss(y_test, y_pred_prob_logreg)\nconf_matrix = confusion_matrix(y_test, y_pred_logreg)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision:\", precision_logreg)\nprint(\"Recall:\", recall_logreg)\nprint(\"F1 Score:\", f1_logreg)\nprint(\"AUC-ROC:\", roc_auc_logreg)\nprint(\"Log Loss:\", logloss_logreg)\nprint(f'True Positives (TP): {TP}')\nprint(f'True Negatives (TN): {TN}')\nprint(f'False Positives (FP): {FP}')\nprint(f'False Negatives (FN): {FN}')\ny_pred_train_logreg = best_model_logreg.predict(X_train)\n\ntrain_accuracy_logreg = accuracy_score(y_train, y_pred_train_logreg)\nprint(\"Train accuracy:\", train_accuracy_logreg)\n\nclass_counts_logreg = y_test.value_counts()\nprint(class_counts_logreg)\n\naccuracy_logreg = accuracy_score(y_pred_logreg, y_test)\nprint(\"Accuracy:\", accuracy_logreg)\n\n# Save results\ndf_results = pd.concat([df_results, pd.DataFrame({\n    \"Model\": [\"Logistic Regression\"],\n    \"Best Train Score\": [best_score_logreg],\n    \"Train Accuracy\": [train_accuracy_logreg],\n    \"Test Accuracy\": [accuracy_logreg],\n    \"Precision\": [precision_logreg],\n    \"Recall\": [recall_logreg],\n    \"F1 Score\": [f1_logreg],\n    \"AUC-ROC\": [roc_auc_logreg],\n    \"Log Loss\": [logloss_logreg],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})], ignore_index=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space_dt = {\n    'max_depth': (1, 50),  # Adjust the upper limit accordingly\n    'min_samples_split': (2, 10),\n    'min_samples_leaf': (1, 10),\n    'max_features': ['sqrt', 'log2', None]\n}\n\n# Initialize Decision Tree Classifier\ndt_classifier = DecisionTreeClassifier()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search_dt = BayesSearchCV(\n    dt_classifier,\n    param_space_dt,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric for decision tree classifier\n    n_jobs=-3\n)\n\n# Fit the Bayesian optimization model\nbayes_search_dt.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params_dt = bayes_search_dt.best_params_\nbest_score_dt = bayes_search_dt.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters:\", best_params_dt)\nprint(\"Best Train Score:\", best_score_dt)\n\n# You can also access the best model via bayes_search_dt.best_estimator_\nbest_model_dt = bayes_search_dt.best_estimator_\n\n# Evaluate the model on the test set\ny_pred_dt = best_model_dt.predict(X_test)\nprecision_dt = precision_score(y_test, y_pred_dt)\nrecall_dt = recall_score(y_test, y_pred_dt)\nf1_dt = f1_score(y_test, y_pred_dt)\nroc_auc_dt = roc_auc_score(y_test, y_pred_dt)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob_dt = best_model_dt.predict_proba(X_test)[:, 1]\nlogloss_dt = log_loss(y_test, y_pred_prob_dt)\nconf_matrix = confusion_matrix(y_test, y_pred_dt)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision:\", precision_dt)\nprint(\"Recall:\", recall_dt)\nprint(\"F1 Score:\", f1_dt)\nprint(\"AUC-ROC:\", roc_auc_dt)\nprint(\"Log Loss:\", logloss_dt)\nprint(f'True Positives (TP): {TP}')\nprint(f'True Negatives (TN): {TN}')\nprint(f'False Positives (FP): {FP}')\nprint(f'False Negatives (FN): {FN}')\ny_pred_train_dt = best_model_dt.predict(X_train)\n\ntrain_accuracy_dt = accuracy_score(y_train, y_pred_train_dt)\nprint(\"Train accuracy:\", train_accuracy_dt)\n\nclass_counts_dt = y_test.value_counts()\nprint(class_counts_dt)\n\naccuracy_dt = accuracy_score(y_pred_dt, y_test)\nprint(\"Accuracy:\", accuracy_dt)\n\n# Save results\ndf_results = pd.concat([df_results, pd.DataFrame({\n    \"Model\": [\"Decision Tree\"],\n    \"Best Train Score\": [best_score_dt],\n    \"Train Accuracy\": [train_accuracy_dt],\n    \"Test Accuracy\": [accuracy_dt],\n    \"Precision\": [precision_dt],\n    \"Recall\": [recall_dt],\n    \"F1 Score\": [f1_dt],\n    \"AUC-ROC\": [roc_auc_dt],\n    \"Log Loss\": [logloss_dt],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})], ignore_index=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the parameter space for Bayesian optimization\nparam_space_rf = {\n    'n_estimators': (10, 300),\n    'max_depth': (1, 50),\n    'min_samples_split': (2, 50),\n    'min_samples_leaf': (1, 50),\n    'max_features': ['sqrt', 'log2', None]\n}\n\n# Initialize Random Forest Classifier\nrf_classifier = RandomForestClassifier()\n\n# Use Bayesian optimization to find the best parameters\nbayes_search_rf = BayesSearchCV(\n    rf_classifier,\n    param_space_rf,\n    n_iter=50,\n    cv=5,\n    scoring='accuracy',  # Scoring metric for random forest classifier\n    n_jobs=-3\n)\n\n# Fit the Bayesian optimization model\nbayes_search_rf.fit(X_train, y_train)\n\n# Get the best parameters and best score\nbest_params_rf = bayes_search_rf.best_params_\nbest_score_rf = bayes_search_rf.best_score_\n\n# Print the results\nprint(\"Best Hyperparameters:\", best_params_rf)\nprint(\"Best Train Score:\", best_score_rf)\n\n# You can also access the best model via bayes_search_rf.best_estimator_\nbest_model_rf = bayes_search_rf.best_estimator_\n\n# Evaluate the model on the test set\ny_pred_rf = best_model_rf.predict(X_test)\nprecision_rf = precision_score(y_test, y_pred_rf)\nrecall_rf = recall_score(y_test, y_pred_rf)\nf1_rf = f1_score(y_test, y_pred_rf)\nroc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n\n# Log Loss requires predicted probabilities, not class labels\ny_pred_prob_rf = best_model_rf.predict_proba(X_test)[:, 1]\nlogloss_rf = log_loss(y_test, y_pred_prob_rf)\nconf_matrix = confusion_matrix(y_test, y_pred_rf)\n\nTN, FP, FN, TP = conf_matrix.ravel()\n\nprint(\"Precision:\", precision_rf)\nprint(\"Recall:\", recall_rf)\nprint(\"F1 Score:\", f1_rf)\nprint(\"AUC-ROC:\", roc_auc_rf)\nprint(\"Log Loss:\", logloss_rf)\nprint(f'True Positives (TP): {TP}')\nprint(f'True Negatives (TN): {TN}')\nprint(f'False Positives (FP): {FP}')\nprint(f'False Negatives (FN): {FN}')\ny_pred_train_rf = best_model_rf.predict(X_train)\n\ntrain_accuracy_rf = accuracy_score(y_train, y_pred_train_rf)\nprint(\"Train accuracy:\", train_accuracy_rf)\n\nclass_counts_rf = y_test.value_counts()\n\naccuracy_rf = accuracy_score(y_pred_rf, y_test)\nprint(\"Accuracy:\", accuracy_rf)\n\n# Save results\ndf_results = pd.concat([df_results, pd.DataFrame({\n    \"Model\": [\"Random Forest\"],\n    \"Best Train Score\": [best_score_rf],\n    \"Train Accuracy\": [train_accuracy_rf],\n    \"Test Accuracy\": [accuracy_rf],\n    \"Precision\": [precision_rf],\n    \"Recall\": [recall_rf],\n    \"F1 Score\": [f1_rf],\n    \"AUC-ROC\": [roc_auc_rf],\n    \"Log Loss\": [logloss_rf],\n    \"TP\": [TP],\n    \"TN\": [TN],\n    \"FP\": [FP],\n    \"FN\": [FN],\n})], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_results","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}